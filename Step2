---
title: "PSTAT126 Project Step-2"
author: "Liuqian Bao"
date: "2023-10-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(tidyverse)
library(tidymodels)
library(modelr)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("skimr")
library("dplyr")
options(max.print=1000000)
library(readxl)
library(ggplot2)
train <- read_excel("C:/Users/baoli/Desktop/PSTAT126/house-prices-advanced-regression-techniques/train.xlsx") 
```

Introduction: We are using the variables BsmtFinSF1 and SalePrice as our variables of interest. 
The BsmtFinSF1 variable is our predictor variable that we will use for hypothesis testing and plotting.
The BsmtFinSF1 variable refers to the basement finished area square feet in the overall housing data.
The SalePrice variable refers to the property's sale price in dollars, and it is our response, or dependent, variable that is affected by BsmtFinSF1.
The original data source is from House Prices - Advanced Regression Techniques from the year 2016 found on Kaggle.
The population that we are inferring our results on are from every property sampled in our data set that is from all residential houses in Ames, Iowa.


Hypothesis: Our hypothesis will be based on our predictor variable, BsmtFinSF1, and the response variable, SalePrice. We will address the
relationship and correlation in our hypthesis, through testing. Our null hypothesis is that BsmtFinSF1 and SalePrice are positively linearly 
related in that B1>0. Our alternative hypothesis is that BsmtFinSF1 and SalePrice are not positively linearly related in that B1<0 or B1=0. 

```{r include=FALSE}
# Variable Selection
train1 <- subset(train, select = -c(MSSubClass, OverallCond, BsmtFinSF2, LowQualFinSF, BsmtHalfBath, YrSold, MoSold, MiscVal, PoolArea, ScreenPorch, EnclosedPorch, KitchenAbvGr, BedroomAbvGr, Street, Alley, Utilities, LandSlope, RoofMatl, BsmtExposure, Heating, CentralAir, MiscFeature, Fence, PoolQC, LandContour,BldgType, Exterior2nd, GarageQual, GarageCond, PavedDrive, SaleType, SaleCondition, GrLivArea, OverallQual, TotalBsmtSF, WoodDeckSF, GarageArea, Fireplaces, TotRmsAbvGrd, MSZoning, Functional, MasVnrArea, GarageYrBlt, YearBuilt, YearRemodAdd))

drop <- c("Condition1","Condition2", "3SsnPorch", "LotFrontage", "1stFlrSF", "2ndFlrSF")
train2 <- train1[,!(names(train1) %in% drop)]
train2
```

```{r}
set.seed(12345)
train2_500 <- train2[sample(1:1460, 500, replace = FALSE),]
```


```{r}
ggplot(data = train2_500, mapping = aes(x = BsmtFinSF1, y = SalePrice)) + 
  geom_point(alpha = 0.1) +
  labs(title="SalePrice vs. GarageCars") +
  xlab("GarageCars") + ylab("SalePrice")
```

#### Linear Model
```{r}
fit <- lm(SalePrice ~ ., train2_500)
fit_BsmtFinSF1 <- lm(SalePrice ~ BsmtFinSF1, train2_500)
summary(fit_BsmtFinSF1)
augment(fit_BsmtFinSF1, train2_500) %>% head(4)
```

```{r, echo = T, fig.width = 8, fig.height = 3}
# panel of residual plots
augment(fit_BsmtFinSF1, train2_500) %>%
  pivot_longer(cols = c(.fitted, BsmtFinSF1)) %>%
  ggplot(aes(y = .resid, x = value)) +
  facet_wrap(~ name, scales = 'free_x') +
  geom_point() +
  geom_hline(aes(yintercept = 0)) +
  geom_smooth(method = 'loess', formula = 'y ~ x', se = F, span = 1)
```

```{r}
# normality check (WITHOUT QUADRATIC)
augment(fit_BsmtFinSF1, train2_500) %>%
  ggplot(aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()
```

#### t-test

```{r}
#finding p value
summary(fit_BsmtFinSF1)$coef
```
We are doing a one sided test, so will divide this by 2.

####confidence interval for beta1(BsmtFinSF1)
```{r}
confint(fit_BsmtFinSF1, 'BsmtFinSF1', level = 0.95)
```

With 95% confidence, a 1 square foot increase in basement square feet is associated with an increase in average sales prices between an estimated 58.24 and 89.14.


####r squared
```{r}
summary(fit_BsmtFinSF1)$adj.r.squared
```

In the following section is our original attempt to use the poly function to adjust linearity. However, we found this is unneeded in this case as the ggplots are very similar.

```{r, echo = T}
# add quadratic term in expenditure
fit_BsmtFinSF1_q <- lm(SalePrice ~ poly(BsmtFinSF1, 2, raw = T), data = train2_500)
```


```{r}
# normality check
augment(fit_BsmtFinSF1_q, train2_500) %>%
  ggplot(aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()
```


#### Plot transformed
```{r}
# ggplot(data = train2_500, mapping = aes(x = poly(BsmtFinSF1, 2, raw = T), y = SalePrice))+
#   geom_point(alpha = 0.1) +
#   labs(title="SalePrice vs. GarageCars") +
#   xlab("GarageCars") + ylab("SalePrice")
```

```{r}
n <- dim(train2_500)[1] # number of observations, or equivalently use nrow(statedata)
p <- 1 # number of predictors
round(coefficients(summary(fit_BsmtFinSF1_q)), 5)
```
