---
title: "New Method"
author: "Liuqian Bao, Stella Ramirez, Andrew Cheng"
date: "2023-12-11"
output:
  pdf_document: default
  html_document: default
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(tidyverse)
library(tidymodels)
library(modelr)
#install.packages("glmnet")
library(glmnet)
```

```{r, include=FALSE}
library("skimr")
library("dplyr")
options(max.print=1000000)
library(readxl)
library(ggplot2)
train <- read_excel("train.xlsx") 
```


```{r include=FALSE}
# Variable Selection
h1 <- subset(train, select = -c(MSSubClass, OverallCond, BsmtFinSF2, LowQualFinSF, BsmtHalfBath, YrSold, MoSold, MiscVal, PoolArea, ScreenPorch, EnclosedPorch, KitchenAbvGr, BedroomAbvGr, Street, Alley, Utilities, LandSlope, RoofMatl, BsmtExposure, Heating, CentralAir, MiscFeature, Fence, PoolQC, LandContour,BldgType, Exterior2nd, GarageQual, GarageCond, PavedDrive, SaleType, SaleCondition, GrLivArea, OverallQual, TotalBsmtSF, WoodDeckSF, GarageArea, Fireplaces, TotRmsAbvGrd, MSZoning, Functional, MasVnrArea, GarageYrBlt, YearBuilt, YearRemodAdd))

h2 <- subset(train, select = c(SalePrice, LotArea, GarageCars, BsmtFinSF1, FullBath, ExterQual, HouseStyle, OpenPorchSF, HalfBath, KitchenQual, GarageFinish))
```

## Innovation: Weighted Least Square 

The analysis technique we have chosen to analyze is the method of weighted least squares. In the previous steps of our project, we explored residual plots and found that our data had heteroscedasticity, or unequal variance. In order to fix that, we took the log of our response variable. Another way in which this issue can be addressed is through weighted linear regression, or the method of weighted least squares. This method places weights on observations so that the ones with smaller error variance are more influential.

In our research, we utilized the website "statology", specifically https://www.statology.org/weighted-least-squares-in-r/, for guidance in how to implement this method.

### Investigate Heteroscedasticity

First, we create our linear model in which we set SalePrice as the response. In the following graph, you can see that there is some fanning of our data points, showing that there is heteroscedasticity. 

```{r, echo=FALSE, fig.cap="Residual vs. Fitted Graph for Linear Model Without log Transformation"}
#usual linear model, without the log transformation
lmod <- lm(SalePrice ~ ., h2)
plot(fitted(lmod), resid(lmod), xlab='Fitted Values', ylab='Residuals')
abline(0,0)
```

#### Summary of Linear Model \newline

The following shows the summary of our linear model, before adding weights.

```{r,echo=FALSE}
summary(lmod)
```
As you can see, the residual standard error is 41080, and the $r^2$ value is 73.66%. 

### Add Weights

To address the potential heteroscedasticity, we define weights(wt) inversely proportional to the squared fitted values of the initial model(lmod). This assigns higher weights to observations with smaller residuals, reducing the influence of potentially less reliable data points.

```{r}
#define weights to use
wt <- 1 / lm(abs(lmod$residuals) ~ lmod$fitted.values)$fitted.values^2

#perform weighted least squares regression
wls_model <- lm(SalePrice ~ ., data = h2, weights=wt)
```


#### View the Summary of the Model, Now with Weights \newline

The following shows the summary of our model, with the weights.

```{r,echo=FALSE}
#view summary of model
summary(wls_model)
``` 

As you can see, with the weighted model, the residual standard error is 1.363, and the $r^2$ value is 75.01%. 

#### Compare With and Without Weights \newline

Comparing the summaries of lmod and wls_model, we observed changes in coefficient estimates, standard errors and $r^2$ values. Especially, the residual standard error shows a drastic change from the model without weights. This means that the values that are predicted with the weighted model are much more accurate and aligned with the actual observations. Also, because the $r^2$ value increased, we know that the weighted model is able to explain more of the variance in SalePrice.



